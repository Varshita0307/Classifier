{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/varshi/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import merge, Input\n",
    "from keras.models import Model,Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/varshi/Desktop/asaa.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-44d1a223a96b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/varshi/Desktop/asaa.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/varshi/Desktop/asaa.jpg'"
     ]
    }
   ],
   "source": [
    "img_path = '/home/varshi/Desktop/asaa.jpg'\n",
    "img = image.load_img(img_path, target_size=(112, 112))\n",
    "x = image.img_to_array(img)\n",
    "print (x.shape)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print (x.shape)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/varshi/Documents/hand/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-Empty\n",
      "\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Loaded the images of dataset-Product Picked\n",
      "\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n",
      "Input image shape: (1, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir('/home/varshi/Documents/hand/Data'+'/'+dataset)\n",
    "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tfor img in img_list:\n",
    "\t\timg_path = data_path + '/'+ dataset + '/'+ img\n",
    "\t\timg = image.load_img(img_path, target_size=(112, 112))\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "#\t\tx = x/255\n",
    "\t\timg_data_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(273, 1, 112, 112, 3)\n",
      "(1, 273, 112, 112, 3)\n",
      "(273, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "#img_data = img_data.astype('float32')\n",
    "print (img_data.shape)\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_of_samples = img_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([0]*int((num_of_samples//2.25)) +  [1] * int((num_of_samples//1.79)))\n",
    "labels.shape\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Empty', 'Product Picked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = np_utils.to_categorical(labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1\n",
      " 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 0 1 1 0 1 1 0 1 1 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "x,y = shuffle(img_data,labels, random_state=2)\n",
    "print(y)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(112,112, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 112, 112, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top=False,weights='imagenet',input_tensor = image_input)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 112, 112, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 15,321,410\n",
      "Trainable params: 15,321,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "last_layer = model.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(128, activation='relu', name='fc1')(x)\n",
    "x = Dense(128, activation='relu', name='fc2')(x)\n",
    "out = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "custom_vgg_model2 = Model(image_input, out)\n",
    "custom_vgg_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in custom_vgg_model2.layers[:-3]:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 112, 112, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 15,321,410\n",
      "Trainable params: 606,722\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "custom_vgg_model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model2.compile(loss='binary_crossentropy',optimizer='adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/varshi/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/varshi/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 218 samples, validate on 55 samples\n",
      "Epoch 1/12\n",
      "218/218 [==============================] - 9s 43ms/step - loss: 1.3036 - accuracy: 0.8578 - val_loss: 0.6466 - val_accuracy: 0.9273\n",
      "Epoch 2/12\n",
      "218/218 [==============================] - 16s 74ms/step - loss: 0.5341 - accuracy: 0.9404 - val_loss: 0.3362 - val_accuracy: 0.9455\n",
      "Epoch 3/12\n",
      "218/218 [==============================] - 16s 72ms/step - loss: 0.2715 - accuracy: 0.9771 - val_loss: 0.5960 - val_accuracy: 0.9455\n",
      "Epoch 4/12\n",
      "218/218 [==============================] - 13s 59ms/step - loss: 0.1464 - accuracy: 0.9862 - val_loss: 0.5434 - val_accuracy: 0.9455\n",
      "Epoch 5/12\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5434 - val_accuracy: 0.9455\n",
      "Epoch 6/12\n",
      "218/218 [==============================] - 11s 51ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5434 - val_accuracy: 0.9455\n",
      "Epoch 7/12\n",
      "218/218 [==============================] - 11s 52ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5433 - val_accuracy: 0.9455\n",
      "Epoch 8/12\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5433 - val_accuracy: 0.9455\n",
      "Epoch 9/12\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5432 - val_accuracy: 0.9455\n",
      "Epoch 10/12\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5432 - val_accuracy: 0.9455\n",
      "Epoch 11/12\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5431 - val_accuracy: 0.9455\n",
      "Epoch 12/12\n",
      "218/218 [==============================] - 11s 50ms/step - loss: 0.1411 - accuracy: 0.9908 - val_loss: 0.5430 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "hist = custom_vgg_model2.fit(X_train, y_train, batch_size=16, epochs=12, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 112, 112, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 112, 112, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model2.save('/home/varshi/Documents/hand/CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
